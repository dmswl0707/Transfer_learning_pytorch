{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "setting.ipynb의 사본",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyP0qfts13WxBbrv1qG7FQtn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmswl0707/transfer-learning_pytorch/blob/main/setting_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S462FkwKg9p4"
      },
      "source": [
        "#image_net사용\n",
        "#classifier만 변형\n",
        "\n",
        "from __future__ import print_function, division\n",
        "#주석필요\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler #학습률수정?\n",
        "from torch.autograd import Variable #grad 주석 필요\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms #데이터셋,모델,변형\n",
        "import matplotlib.pyplot as plt \n",
        "import time #주석필요\n",
        "import os #시스템 주석필요\n",
        "import copy\n",
        "\n",
        "plt.ion() #interactive model\n",
        "\n",
        "##데이터 불러오기-torchvision, torch.utils.data\n",
        "\n",
        "###학습을 위한 데이터 증가(augmentation)과 일반화하기\n",
        "data_transform={\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(), #주석\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val':transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir='C:/Users/choieunji/Desktop/hymenoptera_data'\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transform[x])\n",
        "                  for x in ['train', 'val']}\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GllqLiHS3J0m"
      },
      "source": [
        "###이미지 예제 시각화\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor\"\"\"\n",
        "    inp = inp.numpy().transpose((1,2,0)) #\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std+inp+mean\n",
        "    inp = np.clip(inp, 0, 1) #clip 함수\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001) #업데이트하기 위해 잠시 멈충\n",
        "\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "out=torchvision.utils.make_grid(inputs) #배치 가져오기\n",
        "\n",
        "inshow(out,title=[class_names[x] for x in classes]) #그리드 만들기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgWyQCKt0vky"
      },
      "source": [
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "    \n",
        "    best_model_wts=copy.deepcopy(model.state_dic()) #\n",
        "    best_acc=0.0\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('_'*10)\n",
        "        \n",
        "        #each epoch \n",
        "        for phase in ['train','val']:\n",
        "            if phase == 'train':\n",
        "                schedular.step()\n",
        "                model.train(True)\n",
        "            else:\n",
        "                model.train(False)\n",
        "\n",
        "            running_loss=0.0\n",
        "            running_corrects=0\n",
        "\n",
        "            for data in dataloaders[phase]:\n",
        "                inputs, label = data\n",
        "\n",
        "                if use_gpu:\n",
        "                    inputs = Variable(inputs.cuda())\n",
        "                    labels = Variable(labels.cuda())\n",
        "                else:\n",
        "                    inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                #forward\n",
        "                outputs=model(inputs)\n",
        "                -, preds = torch.max(output.data, 1) #\n",
        "                loss=criterion(outputs, labels) #\n",
        "\n",
        "                if phase=='train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                running_loss +=loss.data[0]*inputs.size(0)\n",
        "                running_corrects +=torch.sum(preds==labels.data) #\n",
        "            \n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            \n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-_BSA1i0xAZ"
      },
      "source": [
        "\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    for i, data in enumerate(dataloaders['val']):\n",
        "        inputs, labels = data\n",
        "        if use_gpu:\n",
        "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
        "        else:\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        for j in range(inputs.size()[0]):\n",
        "            images_so_far += 1\n",
        "            ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "            ax.axis('off')\n",
        "            ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "            imshow(inputs.cpu().data[j])\n",
        "\n",
        "            if images_so_far == num_images:\n",
        "                model.train(mode=was_training)\n",
        "                return\n",
        "    model.train(mode=was_training)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48G8nH9u01G7"
      },
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "if use_gpu:\n",
        "    model_ft = model_ft.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZIUFqUc04eP"
      },
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)\n",
        "\n",
        "visualize_model(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}